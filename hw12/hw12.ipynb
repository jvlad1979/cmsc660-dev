{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LSQClassifier import LSQClassifier\n",
    "from data_utils import get_train_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test(k=20)\n",
    "\n",
    "# model = LSQClassifier(solver='lm')\n",
    "model = LSQClassifier(solver='gauss')\n",
    "# model = LSQClassifier(solver='sgd',solverkwargs={'TOL' : 1e-3,'ITER_MAX' : 600,'batch_size' : 100,'step_size' : 1e-3},verbose=True)\n",
    "\n",
    "model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9912159038372631\n",
      "[[1.134e+03 1.000e+00]\n",
      " [1.800e+01 1.010e+03]]\n"
     ]
    }
   ],
   "source": [
    "from data_utils import accuracy, confusion_matrix\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(accuracy(preds, y_test))\n",
    "print(confusion_matrix(preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6643550624133149\n",
      "[[849. 286.]\n",
      " [440. 588.]]\n",
      "0.9805825242718447\n",
      "[[1125.   10.]\n",
      " [  32.  996.]]\n",
      "0.9852057327785483\n",
      "[[1128.    7.]\n",
      " [  25. 1003.]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m get_train_test(k\u001b[38;5;241m=\u001b[39mk)\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m LSQClassifier(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgauss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     10\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy(preds, y_test)\n",
      "File \u001b[0;32m~/grad/CMSC660/cmsc660-dev/hw12/LSQClassifier.py:23\u001b[0m, in \u001b[0;36mLSQClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mr_and_J\u001b[39m(w):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Res_and_Jac(X,y,w)\n\u001b[0;32m---> 23\u001b[0m w,Niter,Loss_vals,gradnorm_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr_and_J\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolverkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m=\u001b[39m w\n",
      "File \u001b[0;32m~/grad/CMSC660/cmsc660-dev/hw12/nllsq_solvers.py:35\u001b[0m, in \u001b[0;36mGaussNewton\u001b[0;34m(Res_and_Jac, x, ITER_MAX, TOL, verbose)\u001b[0m\n\u001b[1;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m step\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Compute new residuals, Jacobian, loss, and gradient\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m r, J \u001b[38;5;241m=\u001b[39m \u001b[43mRes_and_Jac\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m Jtrans \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(J)\n\u001b[1;32m     37\u001b[0m grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(Jtrans, r)\n",
      "File \u001b[0;32m~/grad/CMSC660/cmsc660-dev/hw12/LSQClassifier.py:22\u001b[0m, in \u001b[0;36mLSQClassifier.fit.<locals>.r_and_J\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mr_and_J\u001b[39m(w):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Res_and_Jac\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/grad/CMSC660/cmsc660-dev/hw12/LSQClassifier.py:44\u001b[0m, in \u001b[0;36mLSQClassifier._Res_and_Jac\u001b[0;34m(self, X, y, w)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Res_and_Jac\u001b[39m(\u001b[38;5;28mself\u001b[39m,X,y,w):\n\u001b[0;32m---> 44\u001b[0m     aux \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_myquadratic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     45\u001b[0m     r \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m+\u001b[39m aux)\n\u001b[1;32m     47\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39maux\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m+\u001b[39m aux)\n",
      "File \u001b[0;32m~/grad/CMSC660/cmsc660-dev/hw12/LSQClassifier.py:67\u001b[0m, in \u001b[0;36mLSQClassifier._myquadratic\u001b[0;34m(self, X, y, w)\u001b[0m\n\u001b[1;32m     65\u001b[0m v \u001b[38;5;241m=\u001b[39m w[d2:d2\u001b[38;5;241m+\u001b[39md]\n\u001b[1;32m     66\u001b[0m b \u001b[38;5;241m=\u001b[39m w[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 67\u001b[0m qterm \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;129;43m@W\u001b[39;49m\u001b[38;5;129;43m@np\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# print((qterm + v.T@X.T + b).shape)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m q \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m*\u001b[39m(qterm \u001b[38;5;241m+\u001b[39m v\u001b[38;5;241m.\u001b[39mT\u001b[38;5;129m@X\u001b[39m\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m+\u001b[39m b)\n",
      "File \u001b[0;32m~/grad/CMSC660/cmsc660-dev/.venv/lib64/python3.11/site-packages/numpy/lib/_twodim_base_impl.py:243\u001b[0m, in \u001b[0;36m_diag_dispatcher\u001b[0;34m(v, k)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m m\n\u001b[1;32m    240\u001b[0m _eye_with_like \u001b[38;5;241m=\u001b[39m array_function_dispatch()(eye)\n\u001b[0;32m--> 243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_diag_dispatcher\u001b[39m(v, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (v,)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_diag_dispatcher)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdiag\u001b[39m(v, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from data_utils import accuracy, confusion_matrix\n",
    "accs = {}\n",
    "cms = {}\n",
    "for k in [1,3,5,10,20,50,100,200]:\n",
    "    print(f\"k = {k}\")\n",
    "    X_train, X_test, y_train, y_test = get_train_test(k=k)\n",
    "    model = LSQClassifier(solver='gauss')\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy(preds, y_test)\n",
    "    cm  = confusion_matrix(preds, y_test)\n",
    "    print(accuracy(preds, y_test))\n",
    "    print(confusion_matrix(preds, y_test))\n",
    "    accs[k] = acc\n",
    "    cms[k] = cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD, iter #0: loss = 5.3477e+01, gradnorm = 8.8168e+01\n",
      "SGD, iter #1: loss = 6.3351e+00, gradnorm = 1.1441e+01\n",
      "SGD, iter #2: loss = 4.3402e+00, gradnorm = 2.9928e+00\n",
      "SGD, iter #3: loss = 4.1326e+00, gradnorm = 4.0678e-01\n",
      "SGD, iter #4: loss = 4.1589e+00, gradnorm = 3.4543e-01\n",
      "SGD, iter #5: loss = 4.1864e+00, gradnorm = 3.5687e-01\n",
      "SGD, iter #6: loss = 4.2119e+00, gradnorm = 3.4017e-01\n",
      "SGD, iter #7: loss = 4.2417e+00, gradnorm = 3.8968e-01\n",
      "SGD, iter #8: loss = 4.2747e+00, gradnorm = 3.4386e-01\n",
      "SGD, iter #9: loss = 4.3123e+00, gradnorm = 5.1016e-01\n",
      "SGD, iter #10: loss = 4.3416e+00, gradnorm = 4.1992e-01\n",
      "SGD, iter #11: loss = 4.3738e+00, gradnorm = 4.2325e-01\n",
      "SGD, iter #12: loss = 4.4094e+00, gradnorm = 4.6863e-01\n",
      "SGD, iter #13: loss = 4.4426e+00, gradnorm = 4.1405e-01\n",
      "SGD, iter #14: loss = 4.4784e+00, gradnorm = 3.3493e-01\n",
      "SGD, iter #15: loss = 4.5167e+00, gradnorm = 3.7928e-01\n",
      "SGD, iter #16: loss = 4.5527e+00, gradnorm = 3.6018e-01\n",
      "SGD, iter #17: loss = 4.5926e+00, gradnorm = 3.3053e-01\n",
      "SGD, iter #18: loss = 4.6314e+00, gradnorm = 3.2932e-01\n",
      "SGD, iter #19: loss = 4.6679e+00, gradnorm = 3.2633e-01\n",
      "SGD, iter #20: loss = 4.7110e+00, gradnorm = 4.5551e-01\n",
      "SGD, iter #21: loss = 4.7539e+00, gradnorm = 3.8979e-01\n",
      "SGD, iter #22: loss = 4.7948e+00, gradnorm = 3.6677e-01\n",
      "SGD, iter #23: loss = 4.8382e+00, gradnorm = 3.5800e-01\n",
      "SGD, iter #24: loss = 4.8806e+00, gradnorm = 3.2789e-01\n",
      "SGD, iter #25: loss = 4.9252e+00, gradnorm = 4.3640e-01\n",
      "SGD, iter #26: loss = 4.9701e+00, gradnorm = 5.0001e-01\n",
      "SGD, iter #27: loss = 5.0158e+00, gradnorm = 3.5854e-01\n",
      "SGD, iter #28: loss = 5.0605e+00, gradnorm = 3.1850e-01\n",
      "SGD, iter #29: loss = 5.1043e+00, gradnorm = 3.2219e-01\n",
      "SGD, iter #30: loss = 5.1483e+00, gradnorm = 4.7515e-01\n",
      "SGD, iter #31: loss = 5.1951e+00, gradnorm = 4.1013e-01\n",
      "SGD, iter #32: loss = 5.2432e+00, gradnorm = 3.1921e-01\n",
      "SGD, iter #33: loss = 5.2921e+00, gradnorm = 3.1501e-01\n",
      "SGD, iter #34: loss = 5.3421e+00, gradnorm = 3.4962e-01\n",
      "SGD, iter #35: loss = 5.3971e+00, gradnorm = 6.2576e-01\n",
      "SGD, iter #36: loss = 5.4425e+00, gradnorm = 3.9841e-01\n",
      "SGD, iter #37: loss = 5.4913e+00, gradnorm = 3.1624e-01\n",
      "SGD, iter #38: loss = 5.5439e+00, gradnorm = 3.9504e-01\n",
      "SGD, iter #39: loss = 5.5937e+00, gradnorm = 3.5096e-01\n",
      "SGD, iter #40: loss = 5.6516e+00, gradnorm = 3.7655e-01\n",
      "SGD, iter #41: loss = 5.7074e+00, gradnorm = 5.0782e-01\n",
      "SGD, iter #42: loss = 5.7616e+00, gradnorm = 3.7980e-01\n",
      "SGD, iter #43: loss = 5.8195e+00, gradnorm = 3.1730e-01\n",
      "SGD, iter #44: loss = 5.8787e+00, gradnorm = 4.6473e-01\n",
      "SGD, iter #45: loss = 5.9315e+00, gradnorm = 3.1626e-01\n",
      "SGD, iter #46: loss = 5.9924e+00, gradnorm = 3.1002e-01\n",
      "SGD, iter #47: loss = 6.0506e+00, gradnorm = 4.7738e-01\n",
      "SGD, iter #48: loss = 6.1073e+00, gradnorm = 3.1989e-01\n",
      "SGD, iter #49: loss = 6.1679e+00, gradnorm = 3.5333e-01\n",
      "SGD, iter #50: loss = 6.2295e+00, gradnorm = 4.2159e-01\n",
      "SGD, iter #51: loss = 6.2895e+00, gradnorm = 3.1170e-01\n",
      "SGD, iter #52: loss = 6.3531e+00, gradnorm = 3.9623e-01\n",
      "SGD, iter #53: loss = 6.4170e+00, gradnorm = 3.4357e-01\n",
      "SGD, iter #54: loss = 6.4813e+00, gradnorm = 3.1298e-01\n",
      "SGD, iter #55: loss = 6.5469e+00, gradnorm = 4.8168e-01\n",
      "SGD, iter #56: loss = 6.6055e+00, gradnorm = 3.1990e-01\n",
      "SGD, iter #57: loss = 6.6713e+00, gradnorm = 4.2449e-01\n",
      "SGD, iter #58: loss = 6.7350e+00, gradnorm = 3.6713e-01\n",
      "SGD, iter #59: loss = 6.7993e+00, gradnorm = 3.2568e-01\n",
      "SGD, iter #60: loss = 6.8670e+00, gradnorm = 3.6163e-01\n",
      "SGD, iter #61: loss = 6.9375e+00, gradnorm = 3.1014e-01\n",
      "SGD, iter #62: loss = 7.0034e+00, gradnorm = 4.2962e-01\n",
      "SGD, iter #63: loss = 7.0701e+00, gradnorm = 3.0751e-01\n",
      "SGD, iter #64: loss = 7.1395e+00, gradnorm = 4.2004e-01\n",
      "SGD, iter #65: loss = 7.2059e+00, gradnorm = 3.9816e-01\n",
      "SGD, iter #66: loss = 7.2804e+00, gradnorm = 4.1150e-01\n",
      "SGD, iter #67: loss = 7.3489e+00, gradnorm = 3.1245e-01\n",
      "SGD, iter #68: loss = 7.4214e+00, gradnorm = 5.5339e-01\n",
      "SGD, iter #69: loss = 7.4893e+00, gradnorm = 3.8514e-01\n",
      "SGD, iter #70: loss = 7.5584e+00, gradnorm = 5.8902e-01\n",
      "SGD, iter #71: loss = 7.6268e+00, gradnorm = 3.5510e-01\n",
      "SGD, iter #72: loss = 7.6987e+00, gradnorm = 3.2605e-01\n",
      "SGD, iter #73: loss = 7.7673e+00, gradnorm = 4.4257e-01\n",
      "SGD, iter #74: loss = 7.8395e+00, gradnorm = 3.2977e-01\n",
      "SGD, iter #75: loss = 7.9107e+00, gradnorm = 4.1627e-01\n",
      "SGD, iter #76: loss = 7.9817e+00, gradnorm = 3.1527e-01\n",
      "SGD, iter #77: loss = 8.0634e+00, gradnorm = 3.6283e-01\n"
     ]
    }
   ],
   "source": [
    "from LSQClassifier import LSQClassifier\n",
    "from data_utils import get_train_test\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test(k=8)\n",
    "X_train = (X_train - X_train.min()) / (X_train.max() - X_train.min())\n",
    "def constant_step_size(iter,size=1e-1):\n",
    "    return size # Fixed step size\n",
    "\n",
    "def inverse_scaling(iter, eta0=1e-1, gamma=0.001):\n",
    "    return eta0 / (1 + gamma * iter)\n",
    "\n",
    "def exponential_decay(iter, eta0=1e-2, lam=0.01):\n",
    "    return eta0 * np.exp(-lam * iter)\n",
    "\n",
    "def step_decay(iter, eta0=5e-1, drop=0.5, epochs_drop=10):\n",
    "    return eta0 * (drop ** (iter // epochs_drop))\n",
    "\n",
    "model = LSQClassifier(solver='sgd',solverkwargs={'TOL' : 1e-3,'ITER_MAX' : 600,'batch_size' : 512,'step_size' : inverse_scaling},lam=0.5,verbose=True)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.332871012482663\n",
      "[[669. 466.]\n",
      " [977.  51.]]\n"
     ]
    }
   ],
   "source": [
    "from data_utils import accuracy, confusion_matrix\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(accuracy(preds, y_test))\n",
    "print(confusion_matrix(preds, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
